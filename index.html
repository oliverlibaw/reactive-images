<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Eye Detection</title>
    <style>
        /* Add custom CSS styling here */
    </style>
    <!-- Ignore source map error -->
    <meta name="sourceMapURL" content="">
    <!-- Import compatible TensorFlow.js library for face-api.js -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.7.4"></script>
    <!-- Import face-api.js library from the local file -->
    <script src="face-api.min.js"></script>
</head>
<body>
    <!-- Display image of person with eyes open or closed -->
    <img id="person" src="" alt="Person image" />

    <script>
        // Access the user's webcam
        async function getUserMediaStream() {
            try {
                const constraints = {
                    video: true,
                    audio: false
                };
                return await navigator.mediaDevices.getUserMedia(constraints);
            } catch (err) {
                console.error('Error accessing the webcam:', err);
            }
        }

        // Load the face-api.js models
        async function loadModels() {
            const MODEL_URL = 'https://raw.githubusercontent.com/justadudewhohacks/face-api.js/master/weights';
            await faceapi.loadTinyFaceDetectorModel(MODEL_URL);
            await faceapi.loadFaceLandmarkTinyModel(MODEL_URL);
        }

        // Detect eyes in the webcam feed using the face-api.js library
        async function detectEyes(video) {
            const options = new faceapi.TinyFaceDetectorOptions({ inputSize: 224 });
            const result = await faceapi.detectSingleFace(video, options).withFaceLandmarks(true);

            if (result && result.landmarks) {
                const eyeLeft = result.landmarks.getLeftEye();
                const eyeRight = result.landmarks.getRightEye();

                if (eyeLeft.length && eyeRight.length) {
                    return true;
                }
            }
            return false;
        }

        // Main function to run the eye detection
        async function runEyeDetection() {
            // Access user's webcam
            const stream = await getUserMediaStream();
            const video = document.createElement('video');
            video.srcObject = stream;
            video.onloadedmetadata = () => {
                video.play();
            };

            // Load the face-api.js models
            await loadModels();

            // Run the eye detection and update the image
            const personImage = document.getElementById('person');
            setInterval(async () => {
                const eyesDetected = await detectEyes(video);

                if (eyesDetected) {
                    personImage.src = 'eyes_open.jpg';
                } else {
                    personImage.src = 'eyes_closed.jpg';
                }
            }, 1000);
        }

        // Run the eye detection on page load
        window.addEventListener('load', runEyeDetection);
    </script>
</body>
</html>
